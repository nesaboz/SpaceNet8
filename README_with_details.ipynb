{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceNet8 \n",
    "\n",
    "SSH into a VM of your choice (I use paperspace Core machine that has ML-out-of-the-box, it has `nvidia-docker` installed). **Make sure to immediately open a folder**, opening it later might destroy the existing terminals and reset docker container.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the folders (data, repo, and runs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Download SpaceNet8 repo and build docker image\n",
    "\n",
    "My home folder: **~/Work/SpaceNet8** (`/home/paperspace/` is a home directory `~`).\n",
    "\n",
    "On paperspace machine get our SpaceNet github repo [instructions](https://github.com/nesaboz/SpaceNet8.git):\n",
    "```\n",
    "git clone https://github.com/nesaboz/SpaceNet8.git\n",
    "```\n",
    "\n",
    "\n",
    "Build docker image (will take a few minutes):\n",
    "```\n",
    "sudo nvidia-docker build -t sn8/baseline:1.0 ~/Work/SpaceNet8/docker \n",
    "```\n",
    "There is a way to avoid constant `sudo` but requires messing with some json config files. For now just use `sudo`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Download SpaceNet8 data\n",
    "\n",
    "Let this be folder (create via mkdir): **~/Work/data**\n",
    "\n",
    "Install `awscli`:\n",
    "```\n",
    "pip install awscli\n",
    "```\n",
    "\n",
    "Download the dataset (links also [here](https://spacenet.ai/sn8-challenge/)). Try to download data first and if needed set up aws credentials:\n",
    "Log into [AWS management console](https://aws.amazon.com/console/), under \"Account/Security credentials/\n",
    "Create access key\" get ACCESS_KEY and SECRET_KEY:\n",
    "```\n",
    "aws configure set aws_access_key_id ACCESS_KEY  \n",
    "aws configure set aws_secret_access_key SECRET_KEY\n",
    "```\n",
    "\n",
    "Download training data:\n",
    "```\n",
    "aws s3 cp  s3://spacenet-dataset/spacenet/SN8_floods/tarballs/Germany_Training_Public.tar.gz . \n",
    "aws s3 cp s3://spacenet-dataset/spacenet/SN8_floods/tarballs/Louisiana-East_Training_Public.tar.gz . \n",
    "```\n",
    "testing data:\n",
    "```\n",
    "aws s3 cp  s3://spacenet-dataset/spacenet/SN8_floods/tarballs/Louisiana-West_Test_Public.tar.gz . \n",
    "```\n",
    "\n",
    "Unzip the data, **make sure they all have their own directory**:\n",
    "```\n",
    "tar -xf Germany_Training_Public.tar.gz\n",
    "tar -xf Louisiana-East_Training_Public.tar.gz\n",
    "tar -xf Louisiana-West_Test_Public.tar.gz\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a runs folder\n",
    "\n",
    "```\n",
    "mkdir runs\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run docker container\n",
    "\n",
    "Make sure remote machine in VSCode has open folder, doing this later might destroy the existing terminals and reset docker container.\n",
    "\n",
    "Let's run the container and mount the three folders that we created in previous steps:\n",
    "```\n",
    "sudo nvidia-docker run -v ~/Work/SpaceNet8:/tmp/SpaceNet8 -v ~/Work/data:/tmp/data -v ~/Work/runs:/tmp/runs --ipc=host -it --rm sn8/baseline:1.0 bash\n",
    "```\n",
    "\n",
    "I added `--ipc=host` to the command to avoid shared memory [issue](https://github.com/pytorch/pytorch#docker-image). \n",
    "\n",
    "in general, option `-v /host/path:/container/path` mounts a folder, more options [here](https://docs.docker.com/engine/reference/commandline/run/).\n",
    "\n",
    "the prompt should now look like this `root@<container_id>:/#` and the folders will be mounted in the `/tmp` folder. Rename this terminal window to **Do not delete** and don't delete it since this shuts down the container.\n",
    "\n",
    "To attach to container from VSCode, install \"Remote Development\" extension [pack](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack), then one can attach the container in VSCode by going to a command pallette (Cmd+Shift+P) and typing \"Attach to running container\".\n",
    "\n",
    "To see running containers' info from paperspace machine use:\n",
    "```\n",
    "docker ps\n",
    "```\n",
    "To stop all the docker containers:\n",
    "```\n",
    "docker container stop ID_or_NAME\n",
    "docker container stop $(docker container ls -aq)\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create intermediary data:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python baseline/data_prep/geojson_prep.py --root_dir /tmp/data --aoi_dirs Germany_Training_Public Louisiana-East_Training_Public\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then create masks (this might 5 min):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python baseline/data_prep/create_masks.py --root_dir /tmp/data --aoi_dirs Germany_Training_Public Louisiana-East_Training_Public\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a split:\n",
    "\n",
    "```\n",
    "python baseline/data_prep/generate_train_val_test_csvs.py --root_dir /tmp/data --aoi_dirs Germany_Training_Public Louisiana-East_Training_Public --out_csv_basename sn8_data --val_percent 0.15 --out_dir /tmp/runs\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/validate Foundation Feature Network\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the Foundation network:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python baseline/train_foundation_features.py --train_csv /tmp/runs/sn8_data_train.csv --val_csv /tmp/runs/sn8_data_val.csv --save_dir /tmp/runs --model_name resnet34 --lr 0.0001 --batch_size 1 --n_epochs 1 --gpu 0\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've been running into memory issues and had to reduce the batch size to 1. TODO try larger GPU."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference with Foundation Features Network\n",
    "\n",
    "Write prediction tiffs to be used for postprocessing and generating the submission.csv\n",
    "```\n",
    "python baseline/foundation_eval.py --model_path /tmp/runs/resnet34_lr1.00e-04_bs1_03-05-2023-22-43/best_model.pth --in_csv /tmp/runs/split/sn8_data_val.csv --save_preds_dir /tmp/runs/foundation --gpu 0 --model_name resnet34\n",
    "```\n",
    "\n",
    "Write prediction .pngs for visual inspection of predictions:\n",
    "```\n",
    "python baseline/foundation_eval.py --model_path /tmp/runs/resnet34_lr1.00e-04_bs1_03-05-2023-22-43/best_model.pth --in_csv /tmp/runs/split/sn8_data_val.csv --save_fig_dir /path/to/output/foundation/pngs --gpu 0 --model_name resnet34\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
