{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceNet8 \n",
    "\n",
    "\n",
    "## Remote machine setup\n",
    "\n",
    "To be able to SSH into a VM I use paperspace Core machine that has ML-out-of-the-box, it has `nvidia-docker` installed.\n",
    "\n",
    "I've set up 3 machine [types](https://docs.paperspace.com/core/compute/resources/machine-performance/): \n",
    "- CPU basic\n",
    "- GPU+ (8Gb of GPU memory)\n",
    "- GPU P6000 (24Gb)\n",
    "\n",
    "Every instance had to have shared drive set up (see next section). To mount a shared drive to `share` folder via:\n",
    "```zsh\n",
    "sudo mount ~/share  # same as: sudo mount share\n",
    "```\n",
    "Please be patient, it might take up to a minute.\n",
    "\n",
    "To run a docker container:\n",
    "```zsh\n",
    "sudo nvidia-docker run -v ~/share:/tmp/share --ipc=host -it --rm sn8/baseline:1.0 bash\n",
    "```\n",
    "\n",
    "You will have to **re-mount the shared drive** after the instance is restarted, that takes a second though.\n",
    "\n",
    "Shared drive currently has folders: \n",
    "- data (with SpaceNet8 data)\n",
    "- repos (with users repos)\n",
    "- runs (with all meta data and models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a shared drive\n",
    "\n",
    "This has already done and is here for reference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a shared drive\n",
    "\n",
    "Shared drive is an excelent way to share drive accross machines. \n",
    "\n",
    "Machines do have to be on the same **private network**, which is created from a network tab on Paperspace Core.\n",
    "\n",
    "Once private network is created **instances MUST be assigned to that private network, this is not a default**. \n",
    "\n",
    "Note there **might be a delay** for all of this to set up (likely <10 minutes) to be able to ssh into a machine.\n",
    "\n",
    "Once you ssh, you will need several pieces of information, follow [this](https://docs.paperspace.com/core/compute/how-to/mounting-shared-drives/#linux), these are the commands you will be using:\n",
    "\n",
    "I've used SHARE_FOLDERNAME as `/home/paperspace/share`:\n",
    "\n",
    "```zsh\n",
    "sudo vim /etc/fstab  # use any editor of your choce btw, add the following line at the end: \n",
    "# //YOUR_SHARED_DRIVE_IP/YOURSHARE   SHARE_FOLDERNAME  cifs  user=USERNAME,password=PASSWORD,rw,uid=1000,gid=1000,users 0 0\n",
    "mkdir SHARE_FOLDERNAME  # if doesn't exist\n",
    "sudo chown paperspace:paperspace SHARE_FOLDERNAME  # this is needed ONLY if SHARE_FOLDERNAME is outside your home directory \n",
    "sudo apt-get update\n",
    "sudo apt install cifs-utils\n",
    "sudo mount SHARE_FOLDERNAME  # MUST use sudo here!\n",
    "df\n",
    "```\n",
    "\n",
    "### Download SpaceNet8 repo and build docker image\n",
    "\n",
    "My home folder: **~/share/SpaceNet8** (`/home/paperspace/` is a home directory `~`).\n",
    "\n",
    "On paperspace machine get our SpaceNet github repo [instructions](https://github.com/nesaboz/SpaceNet8.git):\n",
    "```\n",
    "git clone git@github.com:nesaboz/SpaceNet8.git\n",
    "```\n",
    "\n",
    "\n",
    "Build docker image (will take a few minutes):\n",
    "```\n",
    "sudo nvidia-docker build -t sn8/baseline:1.0 ~/share/SpaceNet8/docker \n",
    "```\n",
    "There is a way to avoid constant `sudo` but requires messing with some json config files. For now just use `sudo`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Download SpaceNet8 data\n",
    "\n",
    "Let this be folder (create via mkdir): **~/share/data**\n",
    "\n",
    "Install `awscli`:\n",
    "```zsh\n",
    "sudo apt install awscli\n",
    "# pip install awscli\n",
    "```\n",
    "\n",
    "Download the dataset (links also [here](https://spacenet.ai/sn8-challenge/)). Try to download data first and if needed set up aws credentials:\n",
    "Log into [AWS management console](https://aws.amazon.com/console/), under \"Account/Security credentials/\n",
    "Create access key\" get ACCESS_KEY and SECRET_KEY:\n",
    "```\n",
    "aws configure set aws_access_key_id ACCESS_KEY  \n",
    "aws configure set aws_secret_access_key SECRET_KEY\n",
    "```\n",
    "\n",
    "Download training data and testing data:\n",
    "```\n",
    "aws s3 cp s3://spacenet-dataset/spacenet/SN8_floods/tarballs/Germany_Training_Public.tar.gz . ; aws s3 cp s3://spacenet-dataset/spacenet/SN8_floods/tarballs/Louisiana-East_Training_Public.tar.gz . ; aws s3 cp s3://spacenet-dataset/spacenet/SN8_floods/tarballs/Louisiana-West_Test_Public.tar.gz . \n",
    "```\n",
    "\n",
    "Make 3 directories:\n",
    "```zsh\n",
    "mkdir Germany_Training_Public; mkdir Louisiana-East_Training_Public; mkdir Louisiana-West_Test_Public\n",
    "```\n",
    "\n",
    "Unzip the data, **make sure they all have their own directory**:\n",
    "```\n",
    "tar -xf Germany_Training_Public.tar.gz -C ./Germany_Training_Public; tar -xf Louisiana-East_Training_Public.tar.gz -C ./Louisiana-East_Training_Public; tar -xf Louisiana-West_Test_Public.tar.gz -C ./Louisiana-West_Test_Public\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the tar.gz files since they are no longer needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run docker container\n",
    "\n",
    "Make sure remote machine in VSCode has open folder, doing this later might destroy the existing terminals and reset docker container.\n",
    "\n",
    "Let's run the container and mount the three folders that we created in previous steps:\n",
    "```\n",
    "sudo nvidia-docker run -v ~/share:/tmp/share --ipc=host -it --rm sn8/baseline:1.0 bash\n",
    "```\n",
    "\n",
    "I added `--ipc=host` to the command to avoid shared memory [issue](https://github.com/pytorch/pytorch#docker-image). \n",
    "\n",
    "in general, option `-v /host/path:/container/path` mounts a folder, more options [here](https://docs.docker.com/engine/reference/commandline/run/).\n",
    "\n",
    "the prompt should now look like this `root@<container_id>:/#` and the folders will be mounted in the `/tmp` folder. Rename this terminal window to **Do not delete** and don't delete it since this shuts down the container.\n",
    "\n",
    "To attach to container from VSCode, install \"Remote Development\" extension [pack](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack), then one can attach the container in VSCode by going to a command pallette (Cmd+Shift+P) and typing \"Attach to running container\".\n",
    "\n",
    "To see running containers' info from paperspace machine use:\n",
    "```\n",
    "docker ps\n",
    "```\n",
    "To stop all the docker containers:\n",
    "```\n",
    "docker container stop ID_or_NAME\n",
    "docker container stop $(docker container ls -aq)\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create intermediary data (this will create data/Germany_Training_Public/annotations/prepped_cleaned folder with all sorts of files, see README.md for details):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python baseline/data_prep/geojson_prep.py --root_dir /tmp/share/data --aoi_dirs Germany_Training_Public Louisiana-East_Training_Public\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create masks (this might 5 min):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python baseline/data_prep/create_masks.py --root_dir /tmp/share/data --aoi_dirs Germany_Training_Public Louisiana-East_Training_Public\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a split:\n",
    "\n",
    "```\n",
    "python baseline/data_prep/generate_train_val_test_csvs.py --root_dir /tmp/share/data --aoi_dirs Germany_Training_Public Louisiana-East_Training_Public --out_csv_basename sn8_data --val_percent 0.15 --out_dir /tmp/share/runs\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/validate Foundation Feature Network\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the Foundation network:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python baseline/train_foundation_features.py --train_csv /tmp/share/runs/sn8_data_train.csv --val_csv /tmp/share/runs/sn8_data_val.csv --save_dir /tmp/share/runs/foundation --model_name resnet34 --lr 0.0001 --batch_size 4 --n_epochs 1 --gpu 0 --checkpoint (optional path/to/model_checkpoint.pth)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P6000 can ran batch size of 4 (8 throws an error). GPU+ can run only batch size of 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference with Foundation Features Network\n",
    "\n",
    "Write prediction tiffs to be used for postprocessing and generating the submission.csv\n",
    "```\n",
    "python baseline/foundation_eval.py --model_path /tmp/share/runs/resnet34_lr1.00e-04_bs4_07-05-2023-07-41/best_model.pth --in_csv /tmp/share/runs/split/sn8_data_val.csv --save_preds_dir /tmp/share/runs/foundation/resnet34_lr1.00e-04_bs4_07-05-2023-07-41/tiffs --gpu 0 --model_name resnet34\n",
    "```\n",
    "\n",
    "Write prediction .pngs for visual inspection of predictions:\n",
    "```\n",
    "python baseline/foundation_eval.py --model_path /tmp/share/runs/resnet34_lr1.00e-04_bs4_07-05-2023-07-41/best_model.pth --in_csv /tmp/share/runs/split/sn8_data_val.csv --save_fig_dir /tmp/share/runs/foundation/resnet34_lr1.00e-04_bs4_07-05-2023-07-41/pngs --gpu 0 --model_name resnet34\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Train/Validate Flood Features Network  \n",
    "\n",
    "```zsh\n",
    "python baseline/train_flood.py --train_csv /tmp/share/runs/sn8_data_train.csv --val_csv /tmp/share/runs/sn8_data_val.csv --save_dir /tmp/share/runs/flood --model_name resnet34_siamese --lr 0.0001 --batch_size 2 --n_epochs 1 --gpu 0\n",
    "```\n",
    "(on P6000, got memory issue with batch size of 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
